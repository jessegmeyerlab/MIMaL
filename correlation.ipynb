{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import snap\n",
    "import scipy\n",
    "import csv\n",
    "import networkx as nx\n",
    "#pro_train_all = pd.read_pickle('pro_train_all.pickle')\n",
    "#lip_train_all = pd.read_pickle('lip_train_all.pickle')\n",
    "#met_train_all = pd.read_pickle('met_train_all.pickle')\n",
    "#ml_train_all = pd.read_pickle('ml_train_all.pickle')\n",
    "\n",
    "#pro_train = pd.read_pickle('pro_train.pickle')\n",
    "#lip_train = pd.read_pickle('lip_train.pickle')\n",
    "#met_train = pd.read_pickle('met_train.pickle')\n",
    "#ml_train = pd.read_pickle('ml_train.pickle')\n",
    "\n",
    "#pro_val = pd.read_pickle('pro_val.pickle')\n",
    "#lip_val = pd.read_pickle('lip_val.pickle')\n",
    "#met_val = pd.read_pickle('met_val.pickle')\n",
    "#ml_val = pd.read_pickle('ml_val.pickle')\n",
    "picklepath = 'C:\\\\Users\\\\qdickinson\\\\Jupyter Notebooks\\\\yeast_multiomics_impute_SHAP\\\\pickles\\\\'\n",
    "#pro_test = pd.read_pickle(picklepath+'pro_test.pickle')\n",
    "#lip_test = pd.read_pickle(picklepath+'lip_test.pickle')\n",
    "#met_test = pd.read_pickle(picklepath+'met_test.pickle')\n",
    "#ml_test = pd.read_pickle('ml_test.pickle')\n",
    "\n",
    "met_all = pd.read_pickle(picklepath+'met_all.pickle')\n",
    "\n",
    "pro_all = pd.read_pickle(picklepath+'pro_all.pickle')\n",
    "\n",
    "pro_all_clean_names = pro_all\n",
    "pro_all_clean_names.columns = [name.split(' ')[0] for name in pro_all_clean_names.columns.values.tolist()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "shap_dict =  pickle.load( open( picklepath+\"shap_pmet_all.pickle\", \"rb\" ) )\n",
    "shap_values=np.asarray(list(shap_dict.values()))\n",
    "met_all_names = met_all.columns.values.tolist()\n",
    "##pro_train_clean_names = pro_train\n",
    "#pro_train_clean_names.columns = [name.split(' ')[0] for name in pro_train_clean_names.columns.values.tolist()]\n",
    "#pro_test_clean_names = pro_test\n",
    "#pro_test_clean_names.columns = [name.split(' ')[0] for name in pro_test_clean_names.columns.values.tolist()]\n",
    "\n",
    "pro_all_clean_names_resp = pro_all_clean_names.filter(like='resp', axis=0)\n",
    "pro_all_clean_names_ferm = pro_all_clean_names.filter(like='ferm', axis=0)\n",
    "\n",
    "#protestlist = pro_test_clean_names.values.tolist()\n",
    "#protestlistnames = pro_test_clean_names.columns.tolist()\n",
    "\n",
    "proalllist = pro_all_clean_names.values.tolist()\n",
    "proalllistnames = pro_all_clean_names.columns.tolist()\n",
    "\n",
    "proallresplist = pro_all_clean_names_resp.values.tolist()\n",
    "proallresplistnames = pro_all_clean_names_resp.columns.tolist()\n",
    "\n",
    "proallfermlist = pro_all_clean_names_ferm.values.tolist()\n",
    "proallfermlistnames = pro_all_clean_names_ferm.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proallresplistarray = []\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "while i < len(proallresplist):\n",
    "    j=0\n",
    "    while j < len(proallresplist[i]):\n",
    "        if len(proallresplistarray)<len(proallresplist[0]):\n",
    "            proallresplistarray.append([])\n",
    "        proallresplistarray[j].append(proallresplist[i][j])\n",
    "        j+=1\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proallfermlistarray = []\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "while i < len(proallfermlist):\n",
    "    j=0\n",
    "    while j < len(proallfermlist[i]):\n",
    "        if len(proallfermlistarray)<len(proallfermlist[0]):\n",
    "            proallfermlistarray.append([])\n",
    "        proallfermlistarray[j].append(proallfermlist[i][j])\n",
    "        j+=1\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.stats.multitest as multitest\n",
    "#protein correlation all resp\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "k = 0\n",
    "\n",
    "correlationarray = []\n",
    "j=0\n",
    "while j<len(proallresplistarray):\n",
    "    k=0\n",
    "    print(j/len(proallresplistarray))\n",
    "    while k<len(proallresplistarray):\n",
    "        r, p = scipy.stats.spearmanr(proallresplistarray[j], proallresplistarray[k])\n",
    "        \n",
    "        correlationarray.append([proallresplistnames[j], proallresplistnames[k], p, r])\n",
    "        #print(k/len(shap_values_arrays[i]))\n",
    "        k+=1\n",
    "\n",
    "    \n",
    "    j+=1\n",
    "    \n",
    "df = pd.DataFrame(correlationarray, columns =['Protein 1', 'Protein2', \"pValue\", \"rho\"])\n",
    "\n",
    "\n",
    "i+=1\n",
    "\n",
    "\n",
    "bonferroni = multitest.multipletests(df['pValue'].tolist(), alpha=0.05, method='bonferroni', is_sorted=False, returnsorted=False)\n",
    "bh = multitest.multipletests(df['pValue'].tolist(), alpha=0.05, method='fdr_bh', is_sorted=False, returnsorted=False)\n",
    "df.insert(2, \"bonferroni\", bonferroni[1])\n",
    "df.insert(2, \"bh\", bh[1])\n",
    "df.to_csv(\"pro_all_resp_corr_adj.csv\", sep=',',index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#protein correlation all ferm\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "k = 0\n",
    "\n",
    "correlationarray = []\n",
    "j=0\n",
    "while j<len(proallfermlistarray):\n",
    "    k=0\n",
    "    print(j/len(proallfermlistarray))\n",
    "    while k<len(proallfermlistarray):\n",
    "        r, p = scipy.stats.spearmanr(proallfermlistarray[j], proallfermlistarray[k])\n",
    "        \n",
    "        correlationarray.append([proallfermlistnames[j], proallfermlistnames[k], p, r])\n",
    "        #print(k/len(shap_values_arrays[i]))\n",
    "        k+=1\n",
    "\n",
    "    \n",
    "    j+=1\n",
    "    \n",
    "df = pd.DataFrame(correlationarray, columns =['Protein 1', 'Protein2', \"pValue\", \"rho\"])\n",
    "\n",
    "\n",
    "i+=1\n",
    "\n",
    "bonferroni = multitest.multipletests(df['pValue'].tolist(), alpha=0.05, method='bonferroni', is_sorted=False, returnsorted=False)\n",
    "bh = multitest.multipletests(df['pValue'].tolist(), alpha=0.05, method='fdr_bh', is_sorted=False, returnsorted=False)\n",
    "df.insert(2, \"bonferroni\", bonferroni[1])\n",
    "df.insert(2, \"bh\", bh[1])\n",
    "df.to_csv(\"pro_all_ferm_corr_adj.csv\", sep=',',index=False)\n",
    "dfbonferroni = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbonferronirho = dfbonferroni.loc[abs(dfbonferroni[\"rho\"]) > 0.7]\n",
    "dfbonferronirho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbonferronirho.to_csv(\"pro_all_ferm_corr_adj_bonferronirho.csv\", sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbonferronirho= pd.read_csv(\"C:\\\\Users\\\\qdickinson\\\\Jupyter Notebooks\\\\yeast_multiomics_impute_SHAP\\\\correlation\\\\pro_all_ferm_corr_adj_bonferronirho.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein1 = dfbonferronirho[\"Protein 1\"].tolist()\n",
    "protein2 = dfbonferronirho[\"Protein2\"].tolist()\n",
    "rho = dfbonferronirho[\"rho\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_dict =  pickle.load( open( picklepath+\"shap_pmet_all.pickle\", \"rb\" ) )\n",
    "shap_values=np.asarray(list(shap_dict.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(pro_all_clean_names.to_numpy()[0])\n",
    "\n",
    "signs = []\n",
    "\n",
    "i = 0\n",
    "while i < len(pro_all_clean_names.to_numpy()):\n",
    "    temp = []\n",
    "    j = 0\n",
    "    while j < len(pro_all_clean_names.to_numpy()[0]):\n",
    "        if pro_all_clean_names.to_numpy()[i][j]<0:\n",
    "            temp.append(-1)\n",
    "        else:\n",
    "            temp.append(1)\n",
    "        j+=1\n",
    "    signs.append(temp)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_signs = []\n",
    "k = 0\n",
    "while k < len(shap_values):\n",
    "    temp1 = []\n",
    "    i = 0\n",
    "    while i < len(signs):\n",
    "        temp = []\n",
    "        j = 0\n",
    "        while j < len(signs[0]):\n",
    "            temp.append(signs[i][j]*shap_values[k][i][j])\n",
    "            j+=1\n",
    "        temp1.append(temp)\n",
    "        i+=1\n",
    "    shap_values_signs.append(temp1)\n",
    "    k+=1\n",
    "    \n",
    "shap_values_signs = np.array(shap_values_signs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( shap_values_signs, open( \"shap_values_met_all_signs.pickle\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shap_values_signs = pickle.load(open( picklepath+\"shap_values_met_all_signs.pickle\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = shap_values_signs\n",
    "#shap_values = abs(np.array(shap_values)).mean(axis=1)\n",
    "shap_values = np.array(abs(shap_values)).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( shap_values, open( \"shap_values_met_all_mean_signs.pickle\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#citrateshapdf = pd.DataFrame(zip(list(pro_all_clean_names.columns), shap_values[56], abs(shap_values[56])), columns = [\"name\" , \"shap\", \"magnitude\"])\n",
    "\n",
    "citrateshapdf = pd.DataFrame(zip(list(pro_all_clean_names.columns), shap_values[20], abs(shap_values[20])), columns = [\"name\" , \"shap\", \"magnitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##Connections with shap and correlated proteins\n",
    "citrateshapdf = citrateshapdf.sort_values(by = 'magnitude', ascending = False)\n",
    "sortednames = citrateshapdf[\"name\"].tolist()\n",
    "sortedshap = citrateshapdf[\"shap\"].tolist()\n",
    "\n",
    "sortednames = sortednames[0:20]\n",
    "sortedshap = sortedshap[0:20]\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_node(\"Citric Acid\")\n",
    "i = 0\n",
    "while i < len(sortednames):\n",
    "    G.add_node(sortednames[i])\n",
    "    G.add_edge(\"Citric Acid\", sortednames[i], shap = float(sortedshap[i]), rho = float(0.0))\n",
    "    j = 0\n",
    "    while j < len(protein1):\n",
    "        if protein1[j] == sortednames[i]:\n",
    "            if (rho[j] > 0.7 or rho[j] < -0.7):\n",
    "                G.add_node(protein2[j])\n",
    "                G.add_edge(sortednames[i], protein2[j], shap = float(0.0)  , rho = float(rho[j]))\n",
    "\n",
    "        j+=1\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "labelsdict = {}\n",
    "\n",
    "\n",
    "\n",
    "shappos = [(u, v) for (u, v, d) in G.edges(data=True) if d[\"shap\"] > 0]\n",
    "shapneg = [(u, v) for (u, v, d) in G.edges(data=True) if d[\"shap\"] < 0]\n",
    "corr = [(u, v) for (u, v, d) in G.edges(data=True) if d[\"rho\"] > 0.7]\n",
    "anticorr = [(u, v) for (u, v, d) in G.edges(data=True) if d[\"rho\"] < -0.7]\n",
    "\n",
    "#pos = nx.spring_layout(G, k = 10, iterations = 100)  # positions for all nodes\n",
    "#pos = nx.spring_layout(G,k=1, iterations = 100, pos = {\"Fumaric Acid\" : [5,-5], \"Citric Acid\" : [-5,-5], \"2-Ketoglutaric Acid\" : [5, 5]}, fixed = [\"Fumaric Acid\", \"Citric Acid\",  \"2-Ketoglutaric Acid\"])  # positions for all nodes\n",
    "plt.figure(figsize=(25,25)) \n",
    "# nodes\n",
    "nx.draw_networkx_nodes(G, pos, node_size=100)\n",
    "\n",
    "# edges\n",
    "nx.draw_networkx_edges(G, pos, edgelist=shappos, edge_color=\"g\", width=5)\n",
    "nx.draw_networkx_edges(G, pos, edgelist=shapneg, edge_color=\"r\", width=5)\n",
    "nx.draw_networkx_edges(G, pos, edgelist=corr, edge_color=\"b\", width=5)\n",
    "nx.draw_networkx_edges(G, pos, edgelist=anticorr, edge_color=\"y\", width=5)\n",
    "\n",
    "i = 0\n",
    "while i < len(sortednames):\n",
    "    labelsdict[sortednames[i]] = sortednames[i]\n",
    "    i+=1\n",
    "labelsdict[\"Citric Acid\"] = \"Citric Acid\"\n",
    "    \n",
    "    \n",
    "# labels\n",
    "nx.draw_networkx_labels(G, pos, labels=labelsdict, font_size=36, font_family=\"sans-serif\")\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"plot2-citric-posshaps.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_graphml(G,\"citrate_corr.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
